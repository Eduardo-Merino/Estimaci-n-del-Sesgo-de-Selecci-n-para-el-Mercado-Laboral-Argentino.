{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodología \n",
    "\n",
    "<p style='text-align: justify;'>La metodología empírica que se utilizará para corregir el posible sesgo de selección se basa en el método propuesto por Heckman (1974) empleando los datos de la Encuesta Permanente de Hogares (EPH) correspondientes al tercer trimestre del 2018.</p>\n",
    "\n",
    "<p style='text-align: justify;'>Para la aplicación de esta metodología se procedió primero, a estimar una ecuación de participación, a través del método Probit la cual relaciona la probabilidad de observar el salario de cada individuo a nivel. Segundo, se corrigió la estimación por MCO del sesgo de selección, como propone Heckman, incluyendo en la ecuación de salarios la variable IMR  que cuantifica la probabilidad predicha de observar el salario, la cual es a su vez estimada sobre la base de la ecuación Probit. Obtenidos los coeficientes corregidos podremos realizar la interpretación correcta de los resultados con los cuales rechazaremos o no la hipótesis de la existencia de sesgo de selección, analizaremos los retornos a la educación de los trabajadores argentinos y observaremos si existe una brecha salarial entre hombres y mujeres. Estos tres pasos se realizarán primero sin diferenciación de sexos, luego se tomaran exclusivamente a los hombres y por último a las mujeres.</p>\n",
    "\n",
    "<p style='text-align: justify;'>La estimación empírica del modelo considera dos ecuaciones. La primera, corresponde a la variable de participación la cual es una variable dicotómica del tipo “participa” o “no participa” en términos de ser o no ser observado un ingreso del trabajo. Esta ecuación se interpreta como la forma reducida de un modelo en el cual la decisión de participación depende del salario de reserva y, por lo tanto, de características personales y de capital humano. Esta ecuación se supone lineal en los parámetros y permite estimar la probabilidad predicha de participación de un individuo con ciertas características.</p> \n",
    "\n",
    "<p style='text-align: justify;'>La segunda ecuación corresponde a la estimación del salario como función de variables de capital humano y de la probabilidad de participar en el mercado laboral, que llamamos el inverso de la razon de Mills (IMR). Esta última corresponde a un modelo de determinación de ingresos mediante el modelo de Mincer, corregido por la presencia de sesgo de selección.</p>\n",
    "\n",
    "La siguiente es la especificación de las ecuaciones:\n",
    "\n",
    "(7)  PART= $α_0+ α_1 EDUC+ α_2  EXPER+ α_3  EXPER2+ α_4  JEFEH+ α_5  ECIVIL+ α_6  SPUBLICO+μ $    \n",
    "\n",
    "(8) LP21= $β_0+ β_1 EDUC+ β_2  EXPER+ β_3  EXPER2+ β_4  JEFEH+ β_5  ECIVIL+ β_6  SPUBLICO+ β_7  IMR +τ $             \n",
    "\n",
    "<p style='text-align: justify;'>En la ecuación (7) la variable dependiente PART corresponde a una variable dicotómica que toma el valor 1 cuando la persona obtiene un ingreso positivo y cero en caso contrario;</p>\n",
    "\n",
    "* EDUC son años de estudio formales; al cual le asignaremos 6 años para primario completo, 12 años para secundario completo, 14 para terciario completo y 16 para universitario completo.\n",
    "\n",
    "* EXPER son años de experiencia potencial. La experiencia potencial se mide a través de la aproximación empírica EXPER=Edad-Educ-6. La aplicación de este proxy requiere necesariamente del cumplimiento de dos condiciones, la primera, que el inicio de la vida laboral comienza inmediatamente después de terminada la etapa escolar. La segunda, que la vida laboral debe ser ininterrumpida. Indudablemente, este supuesto es más discutible en el caso de los grupos caracterizados por altas tasas de desempleo.\n",
    "\n",
    "* EXPER2 corresponde a la experiencia al cuadrado, se espera que tenga signo negativo.\n",
    "\n",
    "* JEFEH es una variable dummy que toma el valor 1 si el individuo i es jefe de hogar, y el valor 0 en caso de no serlo.\n",
    "\n",
    "* ECIVIL es una variable dicotómica que representa el estado civil tomando el valor 1 en el caso de que sea casado o conviviente y 0 en los restantes casos.\n",
    "\n",
    "* SPUBLICO es una variable dummy que toma el valor 1 para aquellos que trabajan en el sector público y 0 de otro modo.\n",
    "\n",
    "<p style='text-align: justify;'>En la ecuación (8) LP21 corresponde al logaritmo natural del salario;</p>\n",
    "\n",
    "* IMR es la probabilidad (ajustada) de que el individuo i participe en el mercado del trabajo o en otras palabras el inverso de la razón de Mills.\n",
    "\n",
    "* μ y τ son errores aleatorios que se asumen con media cero y varianza constante.\n",
    "\n",
    "<p style='text-align: justify;'>En el caso de la ecuación (7), se espera que los parámetros asociados a variables que midan cambios en el costo del ocio tengan signo positivo; esto es, un aumento en el valor de dichas variables afectará positivamente la probabilidad de participar en el mercado. Sin embargo, este efecto dependerá del grado de sustitución en el trabajo fuera del mercado entre los miembros de la familia. Es decir, las variables de capital humano deben tener signo positivo, al igual que el parámetro asociado a la variable JEFEH. Por el contrario, los cambios en el ingreso permanente deberían ejercer un efecto negativo sobre la participación.</p>\n",
    "\n",
    "<p style='text-align: justify;'>Con respecto a la ecuación (8), los signos esperados son los típicos de un modelo de capital humano, es decir, los parámetros de educación y experiencia deben tener signo positivo, mientras que la variable experiencia al cuadrado debería tener un efecto negativo y pequeño relativo al parámetro asociado a la variable EXPER.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math as mat\n",
    "import statsmodels as sm\n",
    "import statsmodels.api as sma\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "import scipy.stats as scs\n",
    "\n",
    "# Creamos un DataFrame en Pandas con los datos de la EPH del tercer trimestre del 2018\n",
    "\n",
    "EPH= pd.read_csv('individual_2018.csv',sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Mantenemos sólo las variables que podrían ser relevantes para el estudio\n",
    "\n",
    "EPH = EPH.filter(['REGION', 'AGLOMERADO', 'PONDERA','H15', 'ITF', 'IPCF', 'PONDIH','CH03', \n",
    "                'CH04', 'CH06', 'CH07', 'CH11', 'CH12', 'CH13', 'CH14', \n",
    "                'NIVEL_ED', 'ESTADO','CAT_OCUP','CAT_INAC','PP3E_TOT', 'PP3F_TOT', 'PP04A','PP04C', \n",
    "                'PP05B2_MES', 'PP05B2_ANO', 'PP08D1', 'P21', 'PONDIIO', \n",
    "                'Tot_p12', 'p47T', 'PONDII','T_Vi','PP04D_COD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable PART. Es una variable dummy que toma el valor 1 cuando la persona obtiene un ingreso positivo y 0 en caso contrario\n",
    "EPH['PART']= 0\n",
    "EPH.loc[(EPH.P21>0), 'PART'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable EDUC\n",
    "EPH['EDUC'] = 0\n",
    "\n",
    "# Eliminamos los que no corresponden\n",
    "# Educación especial\n",
    "EPH = EPH.drop(EPH[EPH.CH12==9].index)\n",
    "\n",
    "# Ns./Nr. si finalizó el nivel\n",
    "EPH = EPH.drop(EPH[EPH.CH13==9].index)\n",
    "\n",
    "# Educación especial\n",
    "EPH = EPH.drop(EPH[EPH.CH14==98].index)\n",
    "\n",
    "# Ns./Nr. cuál fue el último nivel aprobado\n",
    "EPH = EPH.drop(EPH[EPH.CH14==99].index)\n",
    "\n",
    "# Reemplazamos los NaN's de CH14 por 0's\n",
    "EPH['CH14'].fillna(0, inplace=True)\n",
    "\n",
    "# Quitamos a los menores de 10 años\n",
    "EPH = EPH.drop(EPH[EPH.ESTADO==4].index)\n",
    "\n",
    "# preescolar incompleto y completa\n",
    "EPH.loc[(EPH.CH12==1) & (EPH.CH13==2), 'EDUC'] = 0\n",
    "EPH.loc[(EPH.CH12==1) & (EPH.CH13==1), 'EDUC'] = 0\n",
    "\n",
    "# primaria incompleta y completa\n",
    "EPH.loc[(EPH.CH12==2) & (EPH.CH13==2), 'EDUC'] = EPH['CH14']\n",
    "EPH.loc[(EPH.CH12==2) & (EPH.CH13==1), 'EDUC'] = 6\n",
    "\n",
    "# egb incompleto y completo\n",
    "EPH.loc[(EPH.CH12==3) & (EPH.CH13==2), 'EDUC'] = EPH['CH14']\n",
    "EPH.loc[(EPH.CH12==3) & (EPH.CH13==1), 'EDUC'] = 9\n",
    "\n",
    "# secundario incompleto y completo\n",
    "EPH.loc[(EPH.CH12==4) & (EPH.CH13==2), 'EDUC'] = EPH['CH14'] + 6\n",
    "EPH.loc[(EPH.CH12==4) & (EPH.CH13==1), 'EDUC'] = 12\n",
    "\n",
    "# polimodal incompleto y completo\n",
    "EPH.loc[(EPH.CH12==5) & (EPH.CH13==2), 'EDUC'] = EPH['CH14'] + 9\n",
    "EPH.loc[(EPH.CH12==5) & (EPH.CH13==1), 'EDUC'] = 12\n",
    "\n",
    "# terciario incompleto y completo\n",
    "EPH.loc[(EPH.CH12==6) & (EPH.CH13==2), 'EDUC'] = EPH['CH14'] + 12\n",
    "EPH.loc[(EPH.CH12==6) & (EPH.CH13==1), 'EDUC'] = 14\n",
    "\n",
    "# universitario incompleto y completo\n",
    "EPH.loc[(EPH.CH12==7) & (EPH.CH13==2), 'EDUC'] = EPH['CH14'] + 12\n",
    "EPH.loc[(EPH.CH12==7) & (EPH.CH13==1), 'EDUC'] = 17\n",
    "\n",
    "# posgrado incompleto y completo\n",
    "EPH.loc[(EPH.CH12==8) & (EPH.CH13==2), 'EDUC'] = EPH['CH14'] + 17\n",
    "EPH.loc[(EPH.CH12==8) & (EPH.CH13==1), 'EDUC'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable EXPER Y EXPER2\n",
    "EPH['EDAD'] = EPH['CH06']\n",
    "EPH['EXPER'] = EPH['EDAD']-EPH['EDUC']-6\n",
    "EPH['EXPER2'] = EPH['EXPER']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable JEFEH. Es una variable dummy que toma el valor 1 cuando el individuo es jefe de hogar y 0 si no lo es.\n",
    "EPH['JEFEH']= 0\n",
    "EPH.loc[(EPH.CH03==1), 'JEFEH'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable ECIVIL. Es una variable dummy que toma el valor 1 si el individuo esta casado o en union y 0 si no lo esta.\n",
    "EPH['ECIVIL']= 0\n",
    "EPH.loc[(EPH.CH07==1), 'ECIVIL'] = 1\n",
    "EPH.loc[(EPH.CH07==2), 'ECIVIL'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable SPUBLICO. Es una variable dummy que toma el valor 1 si el individuo trabaja en el sector publico y 0 en caso contratrio\n",
    "EPH['SPUBLICO']= 0\n",
    "EPH.loc[(EPH.PP04A==1), 'SPUBLICO'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.492522\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Probit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>EPH['PART']</td>   <th>  No. Observations:  </th>  <td> 47880</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>              <td>Probit</td>      <th>  Df Residuals:      </th>  <td> 47873</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Fri, 05 Jul 2019</td> <th>  Pseudo R-squ.:     </th>  <td>0.2708</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>14:31:27</td>     <th>  Log-Likelihood:    </th> <td> -23582.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -32338.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>   -1.3514</td> <td>    0.023</td> <td>  -58.491</td> <td> 0.000</td> <td>   -1.397</td> <td>   -1.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['EDUC']</th>     <td>    0.0143</td> <td>    0.002</td> <td>    7.790</td> <td> 0.000</td> <td>    0.011</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['EXPER']</th>    <td>    0.0969</td> <td>    0.001</td> <td>   65.144</td> <td> 0.000</td> <td>    0.094</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['EXPER2']</th>   <td>   -0.0019</td> <td> 2.61e-05</td> <td>  -71.837</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['JEFEH']</th>    <td>    0.4912</td> <td>    0.015</td> <td>   31.749</td> <td> 0.000</td> <td>    0.461</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['ECIVIL']</th>   <td>    0.1453</td> <td>    0.015</td> <td>    9.639</td> <td> 0.000</td> <td>    0.116</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['SPUBLICO']</th> <td>    1.1282</td> <td>    0.025</td> <td>   45.672</td> <td> 0.000</td> <td>    1.080</td> <td>    1.177</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                          Probit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:            EPH['PART']   No. Observations:                47880\n",
       "Model:                         Probit   Df Residuals:                    47873\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Fri, 05 Jul 2019   Pseudo R-squ.:                  0.2708\n",
       "Time:                        14:31:27   Log-Likelihood:                -23582.\n",
       "converged:                       True   LL-Null:                       -32338.\n",
       "                                        LLR p-value:                     0.000\n",
       "===================================================================================\n",
       "                      coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept          -1.3514      0.023    -58.491      0.000      -1.397      -1.306\n",
       "EPH['EDUC']         0.0143      0.002      7.790      0.000       0.011       0.018\n",
       "EPH['EXPER']        0.0969      0.001     65.144      0.000       0.094       0.100\n",
       "EPH['EXPER2']      -0.0019   2.61e-05    -71.837      0.000      -0.002      -0.002\n",
       "EPH['JEFEH']        0.4912      0.015     31.749      0.000       0.461       0.522\n",
       "EPH['ECIVIL']       0.1453      0.015      9.639      0.000       0.116       0.175\n",
       "EPH['SPUBLICO']     1.1282      0.025     45.672      0.000       1.080       1.177\n",
       "===================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizamos la primera parte del modelo que consiste en estimar una ecuación de participación, la cual relaciona la probabilidad de observar el salario de cada individuo, para poder obtener la inversa del ratio de Mills\n",
    "model = smf.probit(\"EPH['PART'] ~ EPH['EDUC']+ EPH['EXPER'] + EPH['EXPER2'] + EPH['JEFEH'] + EPH['ECIVIL'] + EPH['SPUBLICO'] \", data=EPH\n",
    ").fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados empíricos de la ecuación (7) que se observan en el cuadro anterior muestran que todas las variables son significativas y poseen los signos que se presumían. EXPER y EXPER2 son significativas, y como era de esperarse esta última mencionada pose signo negativo, mostrando el efecto decreciente de la experiencia sobre el salario. Ser jefe de hogar, vivir en pareja o estar casado de igual manera que estar empleado en el sector público aumenta la probabilidad de participar como se preveía. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos y creamos la inversa del ratio de Mill a partir de la regresion anterior.\n",
    "Ypred = model.predict(EPH[['EDUC']]+ EPH[['EXPER']] + EPH[['EXPER2']] + EPH[['JEFEH']] + EPH[['ECIVIL']] + EPH[['SPUBLICO']])\n",
    "EPH['IMR'] = scs.norm.pdf(Ypred)/scs.norm.cdf(Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la variable lP21 y eliminamos los individuos con ingresos iguales o menores a 0\n",
    "EPH = EPH.drop(EPH[EPH.P21<=0].index)\n",
    "EPH['LP21'] = np.log(EPH['P21'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>EPH['LP21']</td>   <th>  R-squared:         </th> <td>   0.239</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.239</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   872.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 05 Jul 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:31:27</td>     <th>  Log-Likelihood:    </th> <td> -21576.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 19444</td>      <th>  AIC:               </th> <td>4.317e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 19436</td>      <th>  BIC:               </th> <td>4.323e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>       <td>    8.5562</td> <td>    0.176</td> <td>   48.575</td> <td> 0.000</td> <td>    8.211</td> <td>    8.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['EDUC']</th>     <td>    0.0719</td> <td>    0.002</td> <td>   43.572</td> <td> 0.000</td> <td>    0.069</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['EXPER']</th>    <td>    0.0154</td> <td>    0.004</td> <td>    3.802</td> <td> 0.000</td> <td>    0.007</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['EXPER2']</th>   <td>   -0.0002</td> <td> 7.68e-05</td> <td>   -2.622</td> <td> 0.009</td> <td>   -0.000</td> <td>-5.09e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['ECIVIL']</th>   <td>    0.2362</td> <td>    0.013</td> <td>   18.385</td> <td> 0.000</td> <td>    0.211</td> <td>    0.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['JEFEH']</th>    <td>    0.1762</td> <td>    0.022</td> <td>    8.074</td> <td> 0.000</td> <td>    0.133</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['SPUBLICO']</th> <td>    0.1360</td> <td>    0.038</td> <td>    3.586</td> <td> 0.000</td> <td>    0.062</td> <td>    0.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EPH['IMR']</th>      <td>   -0.9418</td> <td>    0.237</td> <td>   -3.972</td> <td> 0.000</td> <td>   -1.407</td> <td>   -0.477</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2517.597</td> <th>  Durbin-Watson:     </th> <td>   1.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4686.985</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-0.840</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.720</td>  <th>  Cond. No.          </th> <td>5.92e+04</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 5.92e+04. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:            EPH['LP21']   R-squared:                       0.239\n",
       "Model:                            OLS   Adj. R-squared:                  0.239\n",
       "Method:                 Least Squares   F-statistic:                     872.5\n",
       "Date:                Fri, 05 Jul 2019   Prob (F-statistic):               0.00\n",
       "Time:                        14:31:27   Log-Likelihood:                -21576.\n",
       "No. Observations:               19444   AIC:                         4.317e+04\n",
       "Df Residuals:                   19436   BIC:                         4.323e+04\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================\n",
       "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------\n",
       "Intercept           8.5562      0.176     48.575      0.000       8.211       8.901\n",
       "EPH['EDUC']         0.0719      0.002     43.572      0.000       0.069       0.075\n",
       "EPH['EXPER']        0.0154      0.004      3.802      0.000       0.007       0.023\n",
       "EPH['EXPER2']      -0.0002   7.68e-05     -2.622      0.009      -0.000   -5.09e-05\n",
       "EPH['ECIVIL']       0.2362      0.013     18.385      0.000       0.211       0.261\n",
       "EPH['JEFEH']        0.1762      0.022      8.074      0.000       0.133       0.219\n",
       "EPH['SPUBLICO']     0.1360      0.038      3.586      0.000       0.062       0.210\n",
       "EPH['IMR']         -0.9418      0.237     -3.972      0.000      -1.407      -0.477\n",
       "==============================================================================\n",
       "Omnibus:                     2517.597   Durbin-Watson:                   1.748\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4686.985\n",
       "Skew:                          -0.840   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.720   Cond. No.                     5.92e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 5.92e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizamos la segunda parte del modelo que consiste en corrigir el sesgo de selección en la estimación por MCO, usando el IMR \n",
    "model1 = smf.ols(\"EPH['LP21'] ~ EPH['EDUC']+ EPH['EXPER'] + EPH['EXPER2'] + EPH['ECIVIL'] + EPH['JEFEH'] + EPH['SPUBLICO'] + EPH['IMR']\", data=EPH\n",
    ").fit()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto de la ecuación (8) y sus resultados mostrados en el cuadro N°2, al igual que en los resultados anteriores todas las variables son significativas y mantienen los mismos signos que en la ecuación anterior. La razón inversa de Mills nos dio significativa por lo que existe un sesgo de selección. Al realizar la ecuación (8) sin la variable IMR obtuvimos coeficientes mayores en todas las variables demostrando una vez más un sesgo de selección en la misma. La variable EDUC nos indica que la inversión en un año más de educación aumenta el salario en un 7,2% para los trabajadores argentinos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "Los resultados de la ecuación de Mincer obtenidos en las 3 notebooks muestran que en promedio para los hombres los retornos a la educación son del 7% y para las mujeres un 10%. Sin embargo, si no hay una diferenciación en el sexo la rentabilidad promedio de la educación es del 7.20%.\n",
    "Respecto del sesgo de selección encontramos una fuerte presencia para el mercado laboral masculino, cuya corrección mediante la inversa de la razón de Mills provoca una gran disminución en los coeficientes obtenidos de la ecuación de Mincer, a tal punto que la experiencia deja de ser significativa en la misma.  Esto es debido a que hay una gran concentración de hombres que trabajan en el sector informal con salarios mayormente menores a los que si lo hacen en el sector formal o que poseen salarios de reserva mayores al salario que obtendrían empleándose. Por lo tanto, encontramos que esto un problema de la estructura del mercado laboral masculino argentino.\n",
    "\n",
    "En relación con las mujeres no hay presencia de sesgo de selección, esto podría ser resultado de que la mayoría de las mujeres empleadas lo hacen el sector formal y, por lo tanto, tendrían las mismas características que aquellas que no observadas que son la minoría de este. Para finalizar, una vez mas si no realizamos una diferenciación en el sexo de los trabajadores, también observaremos la existencia del sesgo de selección, pero es debido a la fuerte presencia de este en el mercado laboral masculino como pudimos examinar anteriormente. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
